{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-08-22 23:12:44.288079: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2024-08-22 23:12:44.288115: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1724368366443
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text2text-generation\", model = \"t5-base\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724368370504
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizer\n",
        "generator(\"summarize: Machine Learning in production environments is largely seen as the ultimate goal. Sometimes, deploying models can be difficult when automation is not part of the workflow. Creating a foundational process that is reliable and automated is complex and requires commitment from the team and the organization as a whole\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "[{'generated_text': 'machine learning is a key to a successful production environment . a foundational process'}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724368582373
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment analysis\n",
        "generator(\"sst2 sentence: Automation takes hard work but allows you to have a solid deployment.\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "[{'generated_text': 'positive'}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724368662010
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Questions\n",
        "generator(\"question: Is deploying models into production hard?\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "[{'generated_text': 'not_entailment'}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724368714550
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Translation\n",
        "generator(\"translate English to French: Automation takes hard work but allows you to have a solid deployment\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "[{'generated_text': \"L'automatisation exige beaucoup de travail, mais vous permet d'avoir un d√©\"}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724368755753
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can create other generation objects by calling in other models as well"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_generator = pipeline(\"text-generation\", model = \"gpt2\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbe955db80fa48b88ac28333176e295b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "106882abeb3944f6a96e19e83ed16dd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58887f4bae3744da8497f1137b10651e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb575958332a40d691e12c35f4ecdf5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d6e465b1e3b4e1aa9b1f961959525be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e61dbd903b3d4e6b901b99216853bdf0"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724368919257
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_generator(\"some phrase here was thought to be\", max_new_tokens = 512)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "[{'generated_text': 'some phrase here was thought to be intended as an insult or an insult to the American Indian, the \"Negro\" or simply another form of Native American. The phrase \\'Negro\\' came to be used to define any two persons or any ethnic'}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724368938052
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}